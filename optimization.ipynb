{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization for roboticists\n",
    "### Author: Shivendra Agrawal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to make sense of some popular terms in Optimization ​\n",
    "1. Gradient Descent​\n",
    "2. Steepest Descent​\n",
    "3. Newton's Method​\n",
    "4. Quasi-Newton Methods (like BFGS)​\n",
    "5. Line Search ​\n",
    "6. Adam​\n",
    "7. RMSprop​\n",
    "8. Trust Region\n",
    "9. Interior Point Methods​ (Linear/Quadratic Programming)​\n",
    "10. Simplex Method​\n",
    "11. Branch and Bound & Branch and Cut​\n",
    "12. Barrier Function​\n",
    "13. Non-convex optimization​\n",
    "14. Constrained optimization​\n",
    "15. Gradient free optimization​\n",
    "16. Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipywidgets\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive, interact, IntSlider, fixed, Output, IntText, Button, VBox, FloatSlider\n",
    "from IPython.display import display\n",
    "\n",
    "# Unconstrained non-convex function\n",
    "def f(x):\n",
    "    \"\"\"Objective function.\"\"\"\n",
    "    return x**4 - 3*x**3 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convex or non-convex\n",
    "We can find this for a twice differentiable scalar functions using second-derivative known as Hessian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570d80bc34cc48ea8207b895ff0b1103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=3.0, description='x_max', max=5.0, min=1.0), Output()), _dom_classes=(…"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hessian(x):\n",
    "    \"\"\"Second derivative (Hessian) of the objective function.\"\"\"\n",
    "    return 12*x**2 - 18*x\n",
    "\n",
    "def plot_function(f, second_derivative, x_max=3):\n",
    "    # Generate x values\n",
    "    x = np.linspace(0, x_max, 400)\n",
    "\n",
    "    # Compute f(x) and its second derivative for each x\n",
    "    y = f(x)\n",
    "    y_second_derivative = second_derivative(x)\n",
    "\n",
    "    fig, axs = plt.subplots(2, figsize=(8, 6))\n",
    "\n",
    "    # Plot f(x)\n",
    "    axs[0].plot(x, y, label='f(x) = $x^4 - 3x^3 + 2$')\n",
    "    axs[0].set_title('Function f(x)')\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Plot the second derivative of f(x)\n",
    "    axs[1].plot(x, y_second_derivative, label=\"f''(x) = $12x^2 - 18x$\", color='orange')\n",
    "    axs[1].axhline(0, color='red', linestyle='--')  # This line indicates where the second derivative is zero\n",
    "    axs[1].set_title(\"Second Derivative of f(x)\")\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create an interactive widget for x_max\n",
    "interactive(plot_function, f=fixed(f), second_derivative=fixed(hessian), x_max=(1, 5, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Function and Its Second Derivative\n",
    "\n",
    "In the plots above, we visualize a function \\( f(x) = x^4 - 3x^3 + 2 \\) and its second derivative.\n",
    "\n",
    "##### Function \\( f(x) \\)\n",
    "\n",
    "The first plot showcases the function \\( f(x) \\) against the variable \\( x \\). The function exhibits a shape defined by the equation, where we can identify the local minima and maxima visually.\n",
    "\n",
    "##### Second Derivative of \\( f(x) \\)\n",
    "\n",
    "The second plot showcases the second derivative of \\( f(x) \\), denoted as \\( f''(x) \\). The second derivative informs us about the curvature of the function:\n",
    "\n",
    "- **Positive values** of the second derivative indicate regions where the function is **convex**. In other words, the function curves upwards.\n",
    "  \n",
    "- **Negative values** indicate **concave** regions, where the function curves downwards.\n",
    "\n",
    "- **Zero values** signify potential **inflection points**, where the curvature changes from convex to concave or vice versa.\n",
    "\n",
    "By analyzing the second derivative plot, we can discern where the function is convex or concave. The red dashed line marks the point where \\( f''(x) = 0 \\), which can help in identifying the inflection points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589b9eee8c10430f970db716be6abf13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='epochs', max=20, min=1), Output…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gradient(x):\n",
    "    \"\"\"First derivative of the objective function.\"\"\"\n",
    "    return 4*x**3 - 9*x**2\n",
    "\n",
    "def gradient_descent(lr=0.01, epochs=10, start_x=1.5):\n",
    "    \"\"\"Perform gradient descent optimization.\n",
    "    \n",
    "    Args:\n",
    "    - lr (float): Learning rate.\n",
    "    - epochs (int): Number of iterations.\n",
    "    - start_x (float): Starting value of x.\n",
    "    \n",
    "    Returns:\n",
    "    - list: History of x values during optimization.\n",
    "    - list: History of function values during optimization.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize x with the starting value\n",
    "    x = start_x\n",
    "    \n",
    "    # Lists to store the history of x values and corresponding function values.\n",
    "    x_history = []\n",
    "    f_history = []\n",
    "    \n",
    "    # Gradient descent loop.\n",
    "    for _ in range(epochs):\n",
    "        # Update rule: Move in the opposite direction of the gradient.\n",
    "        # Notice that the learning rate is a constant in this case.\n",
    "        x = x - lr * gradient(x)\n",
    "        \n",
    "        # Store the updated values in the history.\n",
    "        x_history.append(x)\n",
    "        f_history.append(f(x))\n",
    "        \n",
    "    return x_history, f_history\n",
    "\n",
    "def interactive_gradient_descent(epochs=10):\n",
    "    \"\"\"Visualize gradient descent convergence interactively.\"\"\"\n",
    "    x_history, f_history = gradient_descent(epochs=epochs)\n",
    "    x = np.linspace(-1, 3, 400)\n",
    "    y = f(x)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, y, 'r', label=\"f(x)\")\n",
    "    plt.scatter(x_history, f_history, c='blue', s=50, alpha=0.6, label=f'Gradient Descent (Latest f(x)={f_history[-1]:.2f})')\n",
    "    \n",
    "    plt.title('Gradient Descent Convergence')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "interact(interactive_gradient_descent, epochs=IntSlider(min=1, max=20, value=1, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steepest Descent \n",
    "If your function outputs a vector instead of scalar. ​\n",
    "For example – Minimizing the magnitude of a vector. Each component might also have joint constraints and/or interactions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton's method \n",
    "\n",
    "More generally Newton-Raphson method is an iterative method for finding the roots of a differentiable function $f$, which are solutions of the equation $f(x)=0$.\n",
    "In optimization, we try to find the solutions for the first-derivative or zeros of the first-derivative.\n",
    "\n",
    "The update rule is \n",
    "\n",
    "$x = x - gradient(x)/hessian(x)$\n",
    "* It uses not just the slope (the first derivative) but also the curvature (the second derivative or Hessian) to decide which direction to move in and how far to move.\n",
    "* The magnitude of the curvature can give an idea about how \"steep\" or \"flat\" the valley or peak is. When you divide the gradient by the Hessian in Newton's method, you're effectively scaling your step size by how curved the function is at your current point. If the function is very curved, you take smaller steps; if it's flatter, you take larger steps.\n",
    "\n",
    "**Fun-fact:** If you do the quadratic approximation of the function at the current best solution and find its zeros, you will get the same update rule so it is as if you are doing quadratic approximation in each iteration and solving for it.\n",
    "I put this for visualization sake. Actual method doesn't do this approximation just that the update rule is akin to solving for iterative quadratic approximation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ed08a5604b4b65890d885e023d67df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='epochs', max=15, min=1), FloatS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quadratic approximation for Newton's method\n",
    "# (this is only needed for the visualization)\n",
    "def quadratic_approximation(x, x_k):\n",
    "    \"\"\"Compute the quadratic approximation at a given point x_k.\"\"\"\n",
    "    return f(x_k) + gradient(x_k) * (x - x_k) + 0.5 * hessian(x_k) * (x - x_k)**2\n",
    "\n",
    "def newtons_method(epochs=10, start_x=1.5, epsilon=1e-8):\n",
    "    \"\"\"Perform optimization using Newton's method.\"\"\"\n",
    "    x = start_x\n",
    "    x_history = [x]\n",
    "    f_history = [f(x)]\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        if abs(hessian(x)) < epsilon:  # Check if Hessian is too close to zero to avoid divide by zero error\n",
    "            print(\"Hessian too close to zero. Stopping optimization.\")\n",
    "            break\n",
    "            \n",
    "        x = x - gradient(x) / hessian(x)  # This inversion of hessian if it a giant matrix could be expensive\n",
    "        x_history.append(x)\n",
    "        f_history.append(f(x))\n",
    "        \n",
    "    return x_history, f_history\n",
    "\n",
    "def interactive_newtons_method(epochs=10, start_x=1.5):\n",
    "    \"\"\"Visualize Newton's method convergence interactively.\"\"\"\n",
    "    x_history, f_history = newtons_method(epochs=epochs, start_x=start_x)\n",
    "    x = np.linspace(-2, 4, 400)\n",
    "    y = f(x)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Restrict y axis to make the plot more readable\n",
    "    plt.ylim(-10, 40)\n",
    "    \n",
    "    # Plot the original function\n",
    "    plt.plot(x, y, 'r', label=\"f(x)\")\n",
    "    \n",
    "    # Plot the points computed by Newton's method\n",
    "    plt.scatter(x_history, f_history, c='green', s=50, alpha=0.6, \n",
    "                label=f\"Newton's Method (Latest f(x)={f_history[-1]:.2f})\")\n",
    "    \n",
    "    # Plot the quadratic approximation at the latest point\n",
    "    y_approx = quadratic_approximation(x, x_history[-1])\n",
    "    plt.plot(x, y_approx, 'b--', label=\"Quadratic Approximation\")\n",
    "    \n",
    "    plt.title(\"Newton's Method Convergence\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Invoke the interactive widget for Jupyter Notebook.\n",
    "interact(interactive_newtons_method, \n",
    "         epochs=IntSlider(min=1, max=15, value=1, continuous_update=False),\n",
    "         start_x=FloatSlider(min=-2, max=4, value=1.6, step=0.2, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quasi-Newton method (BFGS)\n",
    "\n",
    "Approximates the hessian rather than calculating it and thus speeds up the calculation.\n",
    "\n",
    "## Newton-like Update for Multi-dimensional Optimization\n",
    "\n",
    "Given a function $f(\\mathbf{x})$ where $\\mathbf{x}$ is a vector, the gradient $\\nabla f$ gives the direction of steepest ascent, and the Hessian $H$ provides information about the curvature.\n",
    "\n",
    "The Newton update step in multi-dimensional form is:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{x}_{\\text{new}} &= \\mathbf{x}_{\\text{old}} - H^{-1} \\nabla f(\\mathbf{x}_{\\text{old}})\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\mathbf{x}_{\\text{new}}$ is the updated parameter vector.\n",
    "- $\\mathbf{x}_{\\text{old}}$ is the previous parameter vector.\n",
    "- $H^{-1}$ is the inverse of the Hessian matrix.\n",
    "- $\\nabla f(\\mathbf{x}_{\\text{old}})$ is the gradient of the function evaluated at $\\mathbf{x}_{\\text{old}}$.\n",
    "\n",
    "This update rule essentially adjusts the parameters $\\mathbf{x}$ by moving along the direction of the negative gradient, scaled by the inverse of the Hessian.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b7dde57ac648368e5620414f36e8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='epochs', max=400, min=1), Float…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bfgs(epochs=10, start_x=1.5, epsilon=1e-8, hessian_inv_init=None):\n",
    "    \"\"\"\n",
    "    Perform optimization using the BFGS quasi-Newton method.\n",
    "    \n",
    "    Parameters:\n",
    "    - epochs: Maximum number of iterations.\n",
    "    - start_x: Starting point.\n",
    "    - epsilon: Small value; if gradient magnitude is below this, stop.\n",
    "    - hessian_inv_init: Initial approximation of the inverse Hessian as a 2D matrix.\n",
    "    \n",
    "    Returns:\n",
    "    - x_history: History of x values during optimization.\n",
    "    - f_history: History of function values during optimization.\n",
    "    \"\"\"\n",
    "    # If no initial Hessian inverse approximation is given, initialize with identity.\n",
    "    if hessian_inv_init is None:\n",
    "        hessian_inv_init = np.eye(1)\n",
    "    hessian_inv_approximation = hessian_inv_init.copy()\n",
    "    \n",
    "    x = start_x\n",
    "    x_history = []\n",
    "    f_history = []\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        grad = gradient(x)\n",
    "        if np.linalg.norm(grad) < epsilon:\n",
    "            break\n",
    "        \n",
    "        p = -np.dot(hessian_inv_approximation, grad)\n",
    "        alpha = 0.01\n",
    "        new_x = x + alpha * p # Akin to Newton's method update rule.\n",
    "        \n",
    "        s = np.array(new_x - x).reshape(-1, 1) # Difference between new and old x\n",
    "        y = (gradient(new_x) - grad).reshape(-1, 1) # Difference between new and old gradient\n",
    "        \n",
    "        rho = 1.0 / np.dot(y.T, s)\n",
    "        I = np.eye(hessian_inv_approximation.shape[0])\n",
    "        hessian_inv_approximation = (I - rho * np.dot(s, y.T)) @ hessian_inv_approximation @ (I - rho * np.dot(y, s.T)) + rho * np.dot(s, s.T)\n",
    "        \n",
    "        x = float(new_x)  # Ensure x remains a scalar\n",
    "        \n",
    "        # Store the current point and its function value for visualization at the end of iteration.\n",
    "        x_history.append(x)\n",
    "        f_history.append(f(x))\n",
    "    \n",
    "    return x_history, f_history\n",
    "\n",
    "def interactive_bfgs(epochs=10, start_x=1.5):\n",
    "    x_history, f_history = bfgs(epochs=epochs, start_x=start_x)\n",
    "    x = np.linspace(-2, 4, 400)\n",
    "    y = f(x)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, y, 'r', label=\"f(x)\")\n",
    "    plt.scatter(x_history, f_history, c='blue', s=50, alpha=0.6, label=f\"BFGS Steps (Latest f(x)={f_history[-1]:.2f})\")\n",
    "    plt.title(\"BFGS Method Convergence\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "interact(interactive_bfgs, \n",
    "         epochs=IntSlider(min=1, max=400, value=1, continuous_update=False),\n",
    "         start_x=FloatSlider(min=-2, max=4, value=1.6, step=0.2, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line Search\n",
    "\n",
    "So far we found the 'direction' of update but kept the learning rate $\\alpha$ fixed.\n",
    "The goal of the line search is to adaptively choose the step size $\\alpha$ to ensure a sufficient decrease in the function value at each step.\n",
    "\n",
    "**Procedure**:\n",
    "\n",
    "- We start with a tentative step size, $\\alpha$.\n",
    "- We check if moving from $x$ in the given direction by $\\alpha$ leads to a \"sufficient\" decrease in the function value. \n",
    "- The notion of \"sufficient\" is determined by the Armijo-Goldstein condition:\n",
    "\n",
    "$$\n",
    "f(x + \\alpha \\times \\text{direction}) > f(x) + c \\times \\alpha \\times \\nabla f(x)^T \\times \\text{direction}\n",
    "$$\n",
    "\n",
    "The right side of this inequality is a linear approximation of the function around the point $x$, increased by a fraction $c$ of the expected reduction. If the actual function value on moving by $\\alpha$ in the given direction is more than this, it means the step size is too large and might be overshooting the minimum.\n",
    "- If the above condition is satisfied, we reduce $\\alpha$ by multiplying it with $\\rho$ and check again.\n",
    "- This process continues iteratively until we find an $\\alpha$ that satisfies the condition, ensuring a sufficient decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71364626795a4cf9ac89c6be7f2fe22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='epochs', max=30, min=1), FloatS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def backtracking_line_search(x, direction, alpha=1.0, rho=0.5, c=0.5):\n",
    "    \"\"\"\n",
    "    Perform backtracking line search.\n",
    "    \n",
    "    x: Current position\n",
    "    direction: Descent direction\n",
    "    alpha: Starting step size (default 1.0)\n",
    "    rho: Factor to decrease alpha if insufficient decrease (default 0.5)\n",
    "    c: Fraction of decrease we'd like (default 0.5)\n",
    "    \n",
    "    Returns:\n",
    "    - Optimal step size alpha.\n",
    "    \"\"\"\n",
    "    while f(x + alpha * direction) > f(x) + c * alpha * gradient(x) * direction:\n",
    "        alpha = rho * alpha\n",
    "    return alpha\n",
    "\n",
    "def gradient_descent_with_line_search(epochs=10, start_x=1.5):\n",
    "    x = start_x\n",
    "    x_history = []\n",
    "    f_history = []\n",
    "    alpha_history = []\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        grad = gradient(x)\n",
    "        \n",
    "        # Compute the direction of descent.\n",
    "        p = -grad\n",
    "        \n",
    "        # Use backtracking line search to compute step size.\n",
    "        alpha = backtracking_line_search(x, p)\n",
    "        alpha_history.append(alpha)\n",
    "        \n",
    "        # Update the current point in the direction of descent.\n",
    "        x = x + alpha * p\n",
    "        \n",
    "        # Store the current point and its function value for visualization.\n",
    "        x_history.append(x)\n",
    "        f_history.append(f(x))\n",
    "    \n",
    "    return x_history, f_history, alpha_history\n",
    "\n",
    "def interactive_gd_line_search(epochs=10, start_x=1.5):\n",
    "    x_history, f_history, alpha_history = gradient_descent_with_line_search(epochs=epochs, start_x=start_x)\n",
    "    x = np.linspace(-2, 4, 400)\n",
    "    y = f(x)\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "    \n",
    "    axs[0].plot(x, y, 'r', label=\"f(x)\")\n",
    "    axs[0].scatter(x_history, f_history, c='blue', s=50, alpha=0.6, label=f\"Gradient Descent Steps (Latest f(x)={f_history[-1]:.2f})\")\n",
    "    axs[0].set_title(\"Gradient Descent with Line Search Convergence\")\n",
    "    axs[0].set_xlabel('x')\n",
    "    axs[0].set_ylabel('f(x)')\n",
    "    axs[0].legend(loc='upper left')\n",
    "    axs[0].grid(True)\n",
    "    \n",
    "    axs[1].plot(range(len(alpha_history)), alpha_history, '-o', color=\"green\", label=\"Alpha (Step Size)\")\n",
    "    axs[1].set_title(\"Step Size (Alpha) at each Iteration\")\n",
    "    axs[1].set_xlabel('Iteration')\n",
    "    axs[1].set_ylabel('Alpha')\n",
    "    axs[1].legend(loc='upper right')\n",
    "    axs[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interact(interactive_gd_line_search, \n",
    "         epochs=IntSlider(min=1, max=30, value=1, continuous_update=False),\n",
    "         start_x=FloatSlider(min=-2, max=4, value=-1.0, step=0.2, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSprop\n",
    "\n",
    "* Way be cleverly find the learning rate specifically for deep learning.\n",
    "* It uses the running average of the squares of the gradients.\n",
    "* Maintains a per-parameter learning rate, adjusted by the magnitude of the recent gradients. Parameters associated with frequent high gradients get a reduced learning rate, and those with small gradients get an increased learning rate.\n",
    "\n",
    "- Also helps with vanishing and exploding gradients\n",
    "- Better for nonstationary data by focuing on recent gradients than distant past gradients.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce0849ee146460a823d4db4e65833eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='epochs', max=1000, min=1), Floa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rmsprop(lr=0.1, gamma=0.9, epsilon=1e-8, epochs=100, start_x=1.5): # NOtice a larger learning rate\n",
    "    x = start_x\n",
    "    moving_avg_sq = 0\n",
    "    x_history = []\n",
    "    f_history = []\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        g = gradient(x)\n",
    "        moving_avg_sq = gamma * moving_avg_sq + (1 - gamma) * g**2\n",
    "        x = x - lr / (np.sqrt(moving_avg_sq) + epsilon) * g\n",
    "        \n",
    "        x_history.append(x)\n",
    "        f_history.append(f(x))\n",
    "    \n",
    "    return x_history, f_history\n",
    "\n",
    "# Visualization\n",
    "def interactive_rmsprop(epochs=10, start_x=1.5):\n",
    "    x_history, f_history = rmsprop(epochs=epochs, start_x=start_x)\n",
    "    x = np.linspace(-2, 4, 400)\n",
    "    y = f(x)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, y, 'r', label=\"f(x)\")\n",
    "    plt.scatter(x_history, f_history, c='blue', s=50, alpha=0.6, label=f\"RMSprop Steps (Latest f(x)={f_history[-1]:.2f})\")\n",
    "    plt.title(\"RMSprop Convergence\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "interact(interactive_rmsprop, \n",
    "        epochs=IntSlider(min=1, max=1000, value=1, continuous_update=False),\n",
    "        start_x=FloatSlider(min=-2, max=4, value=-1, step=0.2, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam\n",
    "\n",
    "Combines the ideas of \n",
    "1. RMSprop - By accounting for exponentially decaying average of past squared gradients.\n",
    "2. Momentum - By accounting for an exponentially decaying average of past gradients to retain a small portion of changes from previous changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560809a906a541ada889729e5b665624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='epochs', max=200, min=1), Float…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def adam(lr=0.1, beta1=0.9, beta2=0.999, epsilon=1e-8, epochs=100, start_x=-1):\n",
    "    x = start_x\n",
    "    m = 0  # Moving average of the gradients (momentum).\n",
    "    v = 0  # Moving average of the squared gradients.\n",
    "    t = 0  # Time step.\n",
    "    \n",
    "    x_history = []\n",
    "    f_history = []\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        t += 1\n",
    "        grad = gradient(x)\n",
    "        \n",
    "        m = beta1 * m + (1 - beta1) * grad\n",
    "        v = beta2 * v + (1 - beta2) * grad**2\n",
    "        \n",
    "        m_corr = m / (1 - beta1**t)  # Bias-corrected estimate of the first moment (mean).\n",
    "        v_corr = v / (1 - beta2**t)  # Bias-corrected estimate of the second moment (variance).\n",
    "        \n",
    "        x -= lr * m_corr / (np.sqrt(v_corr) + epsilon)\n",
    "        \n",
    "        x_history.append(x)\n",
    "        f_history.append(f(x))\n",
    "    \n",
    "    return x_history, f_history\n",
    "\n",
    "def interactive_RMSprop_adam(epochs=10, start_x=-1.5):\n",
    "    x_rmsprop, f_rmsprop = rmsprop(epochs=epochs, start_x=start_x)\n",
    "    x_adam, f_adam = adam(epochs=epochs, start_x=start_x)\n",
    "    \n",
    "    x = np.linspace(-2, 4, 400)\n",
    "    y = f(x)\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.plot(x, y, 'r', label=\"f(x)\")\n",
    "    \n",
    "    plt.scatter(x_rmsprop, f_rmsprop, c='blue', s=50, alpha=0.6, label=f\"RMSprop (Latest f(x)={f_rmsprop[-1]:.2f})\")\n",
    "    plt.scatter(x_adam, f_adam, c='green', marker='x', s=50, alpha=0.6, label=f\"Adam (Latest f(x)={f_adam[-1]:.2f})\")\n",
    "    \n",
    "    plt.title(\"RMSprop vs. Adam Convergence\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "interact(interactive_RMSprop_adam, \n",
    "         epochs=IntSlider(min=1, max=200, value=1, continuous_update=False),\n",
    "         start_x=FloatSlider(min=-2, max=4, value=-1.5, step=0.2, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSprop can still do better in some scenarios because of more stability, less memory overhead. For example RMSprop has shown better results in some cases in Deep RL.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trust Region Methods\n",
    "\n",
    "* They are iterative optimization methods that constrain each iteration to lie within a specific region where the optimization model (often a quadratic approximation) is believed to be trustworthy. They can still use gradient descent. They are used instead of line search.\n",
    "\n",
    "**Gradient Descent / Line Search:**\n",
    "- Choose a direction.\n",
    "- Decide how far to step in that direction.\n",
    "\n",
    "**Trust Region:**\n",
    "- Define a region around the current point.\n",
    "- Choose a step and direction simultaneously such that the new point lies within this region.\n",
    "- Adjust the size of the region based on how trustworthy the approximation was.\n",
    "\n",
    "**When to use them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Initialize x, Delta (size of trust region)\n",
    "while not converged:\n",
    "    Form a model Q of the function around x (often a quadratic approximation)\n",
    "    Solve the trust region subproblem: \n",
    "        p = argmin(Q) subject to ||p|| <= Delta\n",
    "    Evaluate the ratio of actual reduction in f to predicted reduction \n",
    "    if the ratio is high:\n",
    "        x = x + p\n",
    "    Adjust Delta based on the ratio (increase if high, decrease if low)\n",
    "'''\n",
    "\n",
    "# Let's do it for a simple quadratic function f(x) = x^2\n",
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "def df(x):\n",
    "    return 2*x # Decrease predicted by the quadratic model\n",
    "\n",
    "def trust_region(epochs=10, initial_delta=1.0, eta=0.2):\n",
    "    x = 1.5  # Starting from x = 1.5 for visualization purposes\n",
    "    x_vals = [x]\n",
    "    f_vals = [f(x)]\n",
    "    delta_vals = [initial_delta]\n",
    "    delta = initial_delta\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        gradient = df(x)\n",
    "        \n",
    "        # If the gradient is very close to zero, break out\n",
    "        if np.abs(gradient) < 1e-8:\n",
    "            break\n",
    "        \n",
    "        model_decrease = 0.5 * gradient**2\n",
    "        \n",
    "        x_new = x - (delta / np.abs(gradient)) * gradient\n",
    "        actual_decrease = f(x) - f(x_new)\n",
    "        \n",
    "        # Protect against division by zero\n",
    "        if model_decrease == 0:\n",
    "            ratio = 0\n",
    "        else:\n",
    "            ratio = actual_decrease / model_decrease\n",
    "        \n",
    "        # Adjust the trust region size based on the ratio\n",
    "        if ratio < 0.9:\n",
    "            delta *= 0.5\n",
    "        elif ratio > 0.99:\n",
    "            delta = min(2.0 * delta, 2*initial_delta)  # capping the maximum size\n",
    "        # if ratio is between 0.9 and 0.99, delta remains unchanged\n",
    "        \n",
    "        x = x_new\n",
    "        x_vals.append(x)\n",
    "        f_vals.append(f(x))\n",
    "        delta_vals.append(delta)\n",
    "    \n",
    "    return x_vals, f_vals, delta_vals\n",
    "\n",
    "def interactive_trust_region(epochs=1):\n",
    "    x_vals, f_vals, delta_vals = trust_region(epochs=10)  # We always compute the whole sequence for simplicity\n",
    "    x_range = np.linspace(-1, 3, 400)\n",
    "    y_range = f(x_range)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x_range, y_range, 'r', label=\"f(x)\")\n",
    "    plt.scatter(x_vals[:epochs+1], f_vals[:epochs+1], c='blue', s=50, alpha=0.6, label=\"Trust Region Steps\")\n",
    "    \n",
    "    # Plot the trust region boundary\n",
    "    for i in range(epochs):\n",
    "        circle = plt.Circle((x_vals[i], f_vals[i]), delta_vals[i], color='b', fill=False, linestyle='--', linewidth=1)\n",
    "        plt.gca().add_artist(circle)\n",
    "    \n",
    "    plt.title(f\"Trust Region Optimization: Epoch {epochs}\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.ylim(-0.5, 3)  # Fixing y-range for better visualization\n",
    "    plt.show()\n",
    "\n",
    "interact(interactive_trust_region, epochs=IntSlider(min=1, max=3, value=1, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least-squares\n",
    "\n",
    "https://www.cvxpy.org/examples/basic/least_squares.html\n",
    "\n",
    "This can be solved analyticall for a small number of data but we will have to rely on convex optimization methods to otherwise solve it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "\n",
    "- Uses just one example to change weights instead of a 'batch' change. \n",
    "- Tends to be very oscillating. \n",
    "- It is usuallyy better to use mini-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation\n",
    "\n",
    "- It's an algorithm to calculate the gradient of the loss function with respect to each weight in the neural network.\n",
    "- In essence, backpropagation computes how much each weight contributes to the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lagrangian Multipliers\n",
    "\n",
    "- Used primarily for equality constraints. \n",
    "- The basic idea is to transform a constrained problem into an unconstrained one by introducing multipliers for each constraint and forming a \"Lagrangian\" function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interior Point Methods\n",
    " - Used to solve **Linear Programming** and **Quadratic Programming**.\n",
    " - At the core uses Newton's Method combined with various strategies such as Barrier Functions for constrained optimization.\n",
    " - Popular open source solvers like  ECOS (Efficient Cone Solver) use this along with many strategies. \n",
    "\n",
    " **Barrier Functions**\n",
    " A barrier function is introduced into the objective function to ensure that the iterative methods stay within the feasible region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-free Optimization\n",
    "\n",
    "Usually means estimating the gradient\n",
    "\n",
    "**STOMP**\n",
    "- STOMP is a gradient-free optimization method.\n",
    "- Instead of computing gradients, uses noisy rollouts to estimate the gradient information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplex Method\n",
    "\n",
    "Used only for Linear Programming where the objective and constraints are linear. \n",
    "It is deterministic in nature and will yeild the same result.\n",
    "\n",
    "Maximize \n",
    "$$ Z = 3x_1 + 4x_2 $$\n",
    "\n",
    "Subject to \n",
    "$$\n",
    "\\begin{align*}\n",
    "2x_1 + x_2 &\\leq 8 \\\\\n",
    "x_1 + 2x_2 &\\leq 6 \\\\\n",
    "x_1, x_2 &\\geq 0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integer Programming\n",
    "\n",
    "- Branch and Bound method is used  where the problem is converted to LP and solved.\n",
    "- The nearest floor and ceiling integer values bound the solution and prune the branches that are not satisfyying the constraints. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-convex Optimization Strategies\n",
    "\n",
    "\n",
    "#### 1. Global Optimization Methods:\n",
    "- **Branch and Bound**: Uses relaxations (often convex) to bound the function value and prune regions of the search space.\n",
    "- **Simulated Annealing**: A probabilistic method that sometimes accepts worse solutions to escape local optima.\n",
    "- **Genetic Algorithms**: Inspired by natural selection, this method employs mutation, crossover, and selection.\n",
    "- **Particle Swarm Optimization**: Mimics the social behavior of birds and fishes, with a group of candidate solutions \"flying\" through the search space.\n",
    "\n",
    "#### 2. Relaxation Techniques:\n",
    "- Convert the problem to a convex one, solve it, and then derive solutions for the original problem.\n",
    "\n",
    "#### 3. Sequential Convex Programming:\n",
    "- Linearizes or convexifies the problem around a point and repeats the process iteratively. **TrajOpt** paper uses this.\n",
    "\n",
    "#### 4. Restart Techniques:\n",
    "- Methods like gradient descent can be started from various initial points to increase the chance of finding the global minimum.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
